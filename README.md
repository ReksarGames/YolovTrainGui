<div align="center">

# ğŸš€ **YDS â€” YOLO Dataset Studio**

## Automatically build YOLO datasets from Twitch streams and videos

<p align="center">
  <a href="README.md">ğŸ‡ºğŸ‡¸ <b>English</b></a> | <a href="docs/README_ru.md">ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
</p>

<p align="center">
  <a href="#"><img alt="Python" src="https://img.shields.io/badge/Python-3.12%2B-FFD43B?logo=python"></a>
  <a href="#"><img alt="Windows" src="https://img.shields.io/badge/Windows-10%20%7C%2011-0078D6?logo=windows"></a>
  <a href="LICENSE"><img alt="License" src="https://img.shields.io/badge/License-MIT-green"></a>
</p>

</div>

## ğŸ¯ **What This Does**

**YDS** downloads Twitch VODs or captures your screen, extracts frames, and uses an existing YOLO model to automatically generate bounding box labels.
The result is a ready-to-use YOLO dataset (images + labels) for training.

**Why?** Creating YOLO datasets by hand is slow and repetitive. YDS automates most of this process while keeping you in control.

---

## ğŸš€ **TL;DR â€” Quick Start**

```
1. ğŸ“¥ Capture screen or download Twitch VOD
2. ğŸ¤– Auto-label frames with YOLO model
3. ğŸ·ï¸ Manually verify & correct labels (add/remove/fix classes)
4. ğŸ“¦ Split into train/val/test
5. âš™ï¸ Train YOLO model built-in
```

> **Note:** Label verification is a manual step where you can add, remove, or fix bounding boxes and classes on every image.

---

## ğŸ® **Core Features**

| Feature | What It Does |
|---------|-------------|
| **ğŸ“¹ StreamCut** | Download Twitch VODs, auto-extract & label frames (fully automated) |
| **ğŸ® Screen Capture** | Record gameplay + auto-label with YOLO (semi-automatic) |
| **ğŸ–Œï¸ Label Verification** | Manual annotation tool â€” add/edit classes on screenshots |
| **ğŸ“¦ Dataset Split** | Auto partition train/val/test with custom ratios |
| **âš™ï¸ Training** | Built-in YOLO training interface |
| **ğŸ“Š ONNX Benchmark** | Test model inference speed & accuracy |

---

## ğŸ› ï¸ **System Requirements**

| Component | Requirement |
|-----------|-------------|
| **OS** | Windows 10/11 (primary), Linux (manual setup) |
| **Python** | 3.12+ |
| **GPU** | Recommended for real-time capture/inference |
| **CUDA** | Tested with 11.8 & 12.8 (newer versions compatible) |

---

## ğŸ“¥ **Installation & Run**

| Platform | Install | Run |
|----------|---------|-----|
| **Windows** | `setup.bat` | `run.bat` |
| **Linux** | `./setup.sh` | `./run.sh` |

---

## ğŸ”„ **Workflows**

### **1ï¸âƒ£ Screen Data Collection**

1. Go to **Dataset Tab** â†’ Click **Start Data Collection**
2. Configure: detection model, threshold, crop size, save interval
3. Frames & labels auto-saved to `output_folder` (see config.json)

![Dataset Collection](docs/images/yds/dataset.png)

---

### **2ï¸âƒ£ Label Verification â€” Manual Correction**

Review and correct AI-generated labels, or add new bounding boxes with assigned classes.

1. Go to **Dataset Tab** â†’ Click **Label Verification**
2. Opens interactive OpenCV window
3. View auto-labeled frames (or unlabeled screenshots)
4. Add new bounding boxes with class assignment
5. Edit or delete existing boxes
6. Save annotations in YOLO format

<details>
<summary><b>âŒ¨ï¸ Keyboard Controls</b> (click to expand)</summary>

| Control | Action |
|---------|--------|
| ğŸ–±ï¸ Right-Click | Add bounding box (current class) |
| ğŸ–±ï¸ Left-Click | Remove box under cursor |
| ğŸ–±ï¸ Drag Corner | Resize box |
| Dropdown | Change class |
| Spacebar | Toggle label visibility |
| N / P | Next / Previous image |
| D | Delete image |
| S | Save changes |
| Q | Quit |

</details>

---

### **3ï¸âƒ£ Split Dataset**

Automatically splits your dataset into `train / val / test` folders using standard YOLO directory structure.

1. Go to **Tools** â†’ **Split Dataset**
2. Select folder with `images/` and `labels/`
3. Click **Split** â†’ Uses fixed ratios: **70% train / 15% val / 15% test**

**Output:**
```
dataset_split/
â”œâ”€â”€ train/  (70%)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ val/    (15%)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ test/   (15%)
    â”œâ”€â”€ images/
    â””â”€â”€ labels/
```

---

### **4ï¸âƒ£ Training**

1. Go to **Training Tab**
2. Select `data.yaml`
3. Set basic parameters: **epochs, image size, batch size**
4. (Optional) Expand **Advanced Options** for augmentation & performance tuning
5. Click **Start Training**

![Training Tab](docs/images/yds/training.PNG)

<details>
<summary><b>âš¡ Advanced Options</b> (click to expand)</summary>

**Augmentation Settings:**
```json
{
  "mosaic": 1.0,        // Multi-scale training
  "mixup": 0.1,         // Image mixing
  "fliplr": 0.5,        // Horizontal flip
  "flipud": 0.0,        // Vertical flip
  "scale": 0.5,         // Random scaling
  "hsv_h": 0.015,       // Hue shift
  "hsv_s": 0.7,         // Saturation
  "hsv_v": 0.4          // Brightness
}
```

**Regularization & Performance:**
```json
{
  "amp": true,          // Automatic Mixed Precision (faster training)
  "patience": 20,       // Early stopping threshold
  "save_period": 10,    // Save checkpoint every N epochs
  "weight_decay": 0.0005
}
```

**Training Output Structure:**
```
runs/valorant/exp1/
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt          # Best model (highest mAP)
â”‚   â””â”€â”€ last.pt          # Last epoch
â”œâ”€â”€ results.csv          # All metrics
â””â”€â”€ plots/
    â”œâ”€â”€ confusion_matrix.png
    â”œâ”€â”€ F1_curve.png
    â”œâ”€â”€ PR_curve.png
    â””â”€â”€ results.png
```

</details>

---

### **5ï¸âƒ£ StreamCut & Auto-Labeling**

**What it does:** Download Twitch VODs, automatically extract frames, run YOLO inference, save labeled dataset.

1. Go to **Tools** â†’ **Open StreamCut**
2. Add Twitch VOD URLs
3. Choose: download quality, YOLO model, detection threshold, worker threads
4. Downloads to `stream/raw_streams`, outputs labeled frames to `stream/dataset`

**How it works:**
- You provide a pre-trained YOLO model
- Tool downloads VOD and splits into segments
- Runs inference on every N frames
- Saves detections as YOLO-format labels
- Result: fully labeled dataset ready for training
- Button "Sync" Ğ¾Ñ‚Ğ¼ĞµÑ‡Ğ°ĞµÑ‚ ÑƒĞ¶Ğµ ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ¸Ğ¼Ñ‹

**Key:** Better input model = better auto-labeled dataset

**StreamCut Interface:**
![StreamCut Processing](docs/images/streamcut/streamcut.PNG)

---

### **ğŸ¤– ONNX Model Benchmarking**

**What it does:** Run inference on multiple ONNX models to compare detection results and model outputs.

1. Go to **Tools** â†’ **Benchmark ONNX Models**
2. Select folder with `.onnx` model files
3. Click **Run Benchmark** â†’ Runs inference on each model with test images
4. Results show per-model comparison table:

```
Model                                    Shape        nCls  #   Classes      Conf1 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1.5kR6.onnx                              [8400, 6]    1     45  0            0.92
CS2 by Kwnema.onnx                       [8400, 7]    3     12  0,2,3        0.85
ABI_v3.onnx                              [8400, 84]   80    28  5,16,24      0.78
```

**Why use it:** Compare how different model architectures and quantizations detect objects in your test images.

---

### **ğŸ“¥ Model Manager**

**What it does:** One-click download of official YOLO weights for quick experimentation.

1. Go to **Tools** â†’ **YOLO Model Download**
2. Select model size: N (nano) / S (small) / M (medium) / L (large) / X (xlarge)
3. Select version: v8 / v10 / v11 / v12
4. Click **Download** â†’ Saves to `models/` folder

**Why use it:** Start training without hunting for model files. Pre-trained weights ready to use immediately.

![Tools and configure](docs/images/yds/tools_plus_configure.PNG)

---

## âš™ï¸ **Configuration**

- **configs/config.json** â€” GUI defaults, dataset collection, label verification settings
- **configs/configStreamCut.json** â€” StreamCut settings (download workers, thresholds, etc.)

Full reference: [docs/HELP.md](docs/HELP.md)

---

## ğŸ“ **Project Structure**

```
YolovTrainGui/
â”‚
â”œâ”€â”€ ğŸ“„ GUI.py                          # Main application
â”œâ”€â”€ ğŸ“„ setup.bat / run.bat             # Windows scripts
â”œâ”€â”€ ğŸ“„ setup.sh / run.sh               # Linux scripts
â”œâ”€â”€ ğŸ“‹ requirements.txt                # Python dependencies
â”œâ”€â”€ ğŸ“– README.md                       # English guide (you are here)
â”‚
â”œâ”€â”€ ğŸ“‚ docs/
â”‚   â”œâ”€â”€ ğŸ“– README_ru.md                # Russian guide
â”‚   â”œâ”€â”€ ğŸ“– HELP.md                     # Configuration reference (English)
â”‚   â””â”€â”€ ğŸ“– HELP_ru.md                  # Configuration reference (Russian)
â”‚
â”œâ”€â”€ ğŸ“‚ Core/                           # Core modules
â”‚   â”œâ”€â”€ ğŸš€ train.py                    # YOLO training pipeline
â”‚   â”œâ”€â”€ ğŸ¬ StreamCut.py                # VOD processor
â”‚   â”œâ”€â”€ ğŸ® semiauto_dataset_collector.py  # Screen capture
â”‚   â”œâ”€â”€ ğŸ–Œï¸ labelConfig.py              # Label verification tool
â”‚   â””â”€â”€ âœ‚ï¸ splitDatasetFiles.py        # Dataset splitter
â”‚
â”œâ”€â”€ ğŸ“‚ configs/                        # Configuration files
â”‚   â”œâ”€â”€ âš™ï¸ config.json                 # Main settings
â”‚   â””â”€â”€ ğŸ¬ configStreamCut.json        # StreamCut settings
â”‚
â”œâ”€â”€ ğŸ“‚ benchmark/                      # Performance testing
â”‚   â”œâ”€â”€ ğŸ“Š benchmark.py                # ONNX benchmarking
â”‚   â”œâ”€â”€ infer_function.py
â”‚   â””â”€â”€ ğŸ“ models/                     # ONNX models
â”‚
â”œâ”€â”€ ğŸ“‚ models/                         # YOLO weights (.pt files)
â”œâ”€â”€ ğŸ“‚ datasets/                       # Training datasets
â”‚
â”œâ”€â”€ ğŸ“‚ stream/                         # StreamCut output
â”‚   â”œâ”€â”€ ğŸ“ raw_streams/                # Downloaded VODs
â”‚   â”œâ”€â”€ ğŸ“ chunks/                     # Split segments
â”‚   â””â”€â”€ ğŸ“ dataset/                    # Labeled output
â”‚
â”œâ”€â”€ ğŸ“‚ runs/                           # Training results
â”‚   â””â”€â”€ ğŸ“ detect/train*/              # Model checkpoints & metrics
â”‚
â”œâ”€â”€ ğŸ“‚ docs/
â”‚   â””â”€â”€ ğŸ“ images/                     # Screenshots & diagrams
â”‚
â””â”€â”€ ğŸ“‚ utils/                          # Utilities
    â””â”€â”€ ğŸ“ ffmpeg/                     # FFmpeg binaries
```

---

## â“ **FAQ**

**Q: Can I use my own YOLO model?**  
A: Yes, provide any `.pt` model file.

**Q: Does it work without GPU?**  
A: Yes, but screen capture and VOD processing will be much slower.

**Q: Can I combine datasets later?**  
A: Yes, all datasets are in standard YOLO format.

**Q: What if I don't have a YOLO model yet?**  
A: Use Model Manager to download v8/v12 presets, or train a basic one first.

**Q: I stopped StreamCut midâ€‘process. What should I do?**  
A: Delete `stream/resume.json` and Ğ¶ĞµĞ»Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ `stream/dataset/` if you plan to reâ€‘run.  
Resume file tracks completed chunks; if you interrupted, it may mark them as finished.

---

## ğŸ‘¥ **Who This Is For**

YDS is a **complete GUI solution** for building YOLO datasets without CLI scripts.

Use YDS if you:
- âœ… Want to build YOLO datasets without manual labeling
- âœ… Work with Twitch streams or gameplay videos
- âœ… Need fast iteration on object detection models
- âœ… Want **all tools in one place** (capture, label, split, train) instead of gluing CLI scripts together
- âœ… Prefer **GUI over command line** for dataset management


---
## ğŸ›£ï¸ Roadmap (Ideas)

- YouTube support for StreamCut
- Custom dataset merge tools
- Linux GUI improvements
- Multi-monitor capture
---


## ğŸ”— **Quick Links**

| Resource | Description |
|----------|-------------|
| [ğŸ“– Configuration Reference](docs/HELP.md) | Detailed config.json & StreamCut settings |
| [ğŸ“– Russian Guide](docs/README_ru.md) | ğŸ‡·ğŸ‡º ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ñ€ÑƒĞºĞ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ |
| [âš™ï¸ Main Config](configs/config.json) | GUI defaults & dataset settings |
| [ğŸ¬ StreamCut Config](configs/configStreamCut.json) | VOD download & processing settings |
| [ğŸ“„ License](LICENSE) | MIT License |

---

<div align="center">

**Made with â¤ï¸ for the computer vision community**

[â­ Star on GitHub](https://github.com/ReksarGames/YolovTrainGui) | [ğŸ› Report Issue](https://github.com/ReksarGames/YolovTrainGui/issues)

**Happy detecting! ğŸš€**

</div>

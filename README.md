<p align="right">
  <a href="README.md">ğŸ‡ºğŸ‡¸ English</a> | <a href="README_ru.md">ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹</a>
</p>

# ğŸš€ YDS â€” YOLO Dataset Studio ğŸ¯

> Interactive toolkit for **collecting**, **labeling**, **splitting**, and **training** object detection datasets for Ultralytics YOLO (v12 and compatible). ğŸ–¥ï¸ğŸ“Š

**YOLO Flow Studio** is a desktop application with a graphical interface (PyQt5) that handles the complete workflow of YOLO dataset management:

[ğŸ“¹ StreamCut â€” automated tool for downloading, splitting, and processing Twitch VOD](https://github.com/ReksarGames/StreamCut)

![GUI](docs/images/gui.png)

- ğŸ¤– Semi-automatic **screen dataset collection** using a pretrained YOLO model.
- âœï¸ **Manual labeling correction** tool.
- ğŸ“‚ **Automatic splitting** into `train/val/test`.
- ğŸ‹ï¸ **Initiating training** of Ultralytics YOLO with configurable hyperparameters.
- ğŸ“ˆ **Real-time logging** of data collection and training progress.

## ğŸŒŸ Features

- ğŸ›ï¸ **Interactive GUI:** PyQt5-based intuitive interface.
- ğŸ§² **Semi-Automatic Dataset Collection:** Automatically captures screen images labeled by pretrained YOLO models.
- ğŸ–ï¸ **Labeling Tool:** Manual labeling corrections via intuitive mouse controls.
- ğŸ“¦ **Dataset Splitting:** Automatically splits datasets into training, validation, and testing sets.
- âš™ï¸ **Configurable Training:** Set epochs, image size, batch size, and more.
- â±ï¸ **Real-time Logging:** Immediate feedback on dataset collection and model training.

## ğŸ› ï¸ Requirements

- Python 3.8+  
- PyQt5  
- OpenCV (`opencv-python`)  
- Ultralytics (`ultralytics`)  
- PyTorch (`torch`)  
- MSS (`mss`), `screeninfo`, `numpy` 

## ğŸ“¥ Installation

```bash
git clone https://github.com/your-repo/YOLOv12-Dataset-Manager.git
cd YOLOv12-Dataset-Manager
pip install -r requirements.txt
```

## ğŸ® Usage

### ğŸš¦ Launching the Application

```bash
python GUI.py
```

### ğŸ”‘ Key Functionalities

- ğŸ“¸ **Data Collection:**
  - Begin automatic image capture and labeling from your screen.
- ğŸ–Œï¸ **Label Correction:**
  - Right-click to add bounding boxes; left-click to remove bounding boxes.
- ğŸ“š **Dataset Management:**
  - Split datasets into `train`, `val`, and `test` subsets automatically.
- ğŸš€ **Model Training:**
  - Adjust training parameters via GUI, then initiate training.

## âš™ï¸ Configuration

Adjust settings in `config.json` or via the GUI:

```json
{
  "model_path": "models/sunxds_0.7.6.pt",
  "classes": ["class_player", "class_head"],
  "grabber": { "crop_size": 0.8, "width": 640, "height": 640 },
  "output_folder": "dataset_output",
  "save_interval": 3,
  "detection_threshold": 0.5,
  "data_folder": "dataset_output",
  "last_data_yaml": "datasets/Valorant/data.yaml"
}
```

### ğŸ§© Steps

1. ğŸ¥ **Data Collection (Semi-Auto)**  
Start screen capture via GUI by pressing `Start Capture`. Captured images and labels will be saved automatically. Press `Stop` to end capture.

2. ğŸ¨ **Manual Label Correction**  
Use the labeling tool accessible via GUI or by running `labelConfig.py`.

- **Right-click** â€” Add bounding box of selected class.
- **Left-click** â€” Remove bounding box under cursor.
- **Class switching** â€” Via GUI class list.

3. ğŸ“ **Dataset Splitting**  
Split dataset via GUI (`Split` button) or command line:

```bash
python splitDatasetFiles.py
```

Default output structure:

```
dataset_output_split/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ test/
    â”œâ”€â”€ images/
    â””â”€â”€ labels/
```

4. ğŸ… **Training**  
Specify the `data.yaml` (with paths to train/val), set hyperparameters (epochs, imgsz, batch) in GUI, and press `Train`.

CLI version:

```bash
python train.py \
  --model models/yolov12s.pt \
  --data datasets/your_dataset/data.yaml \
  --epochs 50 \
  --imgsz 640 \
  --batch 16 \
  --project runs/exp \
  --name auto
```

## ğŸ“Œ Project Structure

```
YOLO-Flow-Studio
â”œâ”€â”€ dataset_output/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ yolov12s.pt
â”œâ”€â”€ GUI.py                  # Main GUI
â”œâ”€â”€ labelConfig.py          # Manual labeling tool
â”œâ”€â”€ semiauto_dataset_collector.py  # Screen capture and auto-labeling
â”œâ”€â”€ splitDatasetFiles.py    # Dataset splitting script
â”œâ”€â”€ train.py                # YOLO training script
â”œâ”€â”€ config.json             # Configuration file
â”œâ”€â”€ LICENSE                 # MIT License
â””â”€â”€ gui.puml                # (optional)

```

---

# ğŸš€ StreamCut

Automated tool for downloading, slicing and processing Twitch VODs ğŸ¥ using YOLO ğŸ¤–.  
It downloads VODs, splits them into timeâ€‘based segments, runs inference on selected frames, and saves only those frames containing your target classesâ€”perfect for building training datasets!

---

## ğŸ“‹ Overview

1. ğŸ“¥ **Download**  
   Parallel VOD download via `yt-dlp`, with archive tracking to avoid duplicates.  
2. ğŸï¸ **Slice**  
   Split each video into `.ts` segments of fixed duration using `ffmpeg`.  
3. ğŸ¤– **Infer**  
   Run YOLO on every Nth frame, save images & labels only when detections occur.  
4. âš™ï¸ **Parallelism**  
   Fully configurable worker pools for each stage: download, slice, inference, save.

---

## âœ¨ Key Features

- **Bulk VOD support** â€” download any number of Twitch VOD URLs.  
- **Selective frame extraction** â€” keeps only frames with nonâ€‘zero detections.  
- **Customizable parallelism** â€” control workers for each pipeline stage.  
- **Download archive** â€” maintains `downloaded.txt` to skip alreadyâ€‘fetched videos.  
- **Resumable processing** â€” optional `resume.json` to pick up where you left off.  
- **Readyâ€‘toâ€‘use dataset**  
  - `stream/dataset/images/*.jpg`  
  - `stream/dataset/labels/*.txt`  

---

## âš™ï¸ Configuration (`config.json`)

```jsonc
{
  "video_sources": [
    "https://www.twitch.tv/videos/2522936875",
    "https://www.twitch.tv/videos/2524662899"
  ],
  "raw_stream_folder":  "stream/raw_streams",    // Downloaded VODs
  "chunks_folder":      "stream/chunks",         // .ts segments
  "output_folder":      "stream/dataset",        // images/ & labels/
  "time_interval":      3,                       // Inference every N frames
  "detection_threshold": 0.3,                    // YOLO confidence threshold
  "model_path":         "models/sunxds_0.7.6.pt",// Path to your .pt model
  "class_map": {
    "player": 0,
    "head":   7
  },

  // ğŸ‘· Worker pools
  "max_download_workers": 2,   // ğŸ›  Parallel downloads (yt-dlp)
  "split_workers":        4,   // ğŸª“ ffmpeg slicing
  "process_workers":      6,   // ğŸ” YOLO inference
  "save_workers":         2,   // ğŸ’¾ Disk writes (images + labels)

  "download_archive":  "stream/downloaded.txt", // Tracks downloaded URLs
  "resume_info_file":  "stream/resume.json"     // Tracks processed segments
}

```

| Parameter              | Emoji | Description                                                | Recommended                           |
| ---------------------- | :---: | ---------------------------------------------------------- | ------------------------------------- |
| `max_download_workers` |   ğŸ›   | Number of parallel `yt-dlp` download threads               | 2â€“4 (avoid saturating your network)   |
| `split_workers`        |   ğŸª“  | Threads for slicing `.ts` files into fixedâ€‘length segments | \~CPU cores                           |
| `process_workers`      |   ğŸ”  | Concurrent YOLO inference processes (one per chunk)        | Based on GPU capacity                 |
| `save_workers`         |   ğŸ’¾  | Threads dedicated to saving images & label files to disk   | 1â€“2 (prevents I/O blocking inference) |

```
ğŸ“‚ Directory Structure

â”œâ”€â”€ StreamCut.py
â”œâ”€â”€ config.json
â”œâ”€â”€ models/
â”‚   â””â”€â”€ sunxds_0.7.6.pt
â””â”€â”€ stream/
    â”œâ”€â”€ raw_streams/      # Downloaded VODs
    â”œâ”€â”€ chunks/           # .ts segments
    â”œâ”€â”€ downloaded.txt    # Archive of fetched URLs
    â”œâ”€â”€ resume.json       # (Optional) resume state
    â””â”€â”€ dataset/
        â”œâ”€â”€ images/       # Saved frames (.jpg)
        â””â”€â”€ labels/       # YOLO labels (.txt)

```

ğŸ“ Notes
+ time_interval is in frames for inference. If you want â€œevery 10 secondsâ€, compute interval_frames = fps * 10.
+ resume.json is created automatically on first runâ€”no manual steps needed.
+ Adjust worker counts based on your hardware (CPU cores for slicing, GPU for inference, disk I/O for saving).